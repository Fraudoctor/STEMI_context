{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# BigQuery settings\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import dbapi;\n",
    "client = bigquery.Client(\"mining-clinical-decisions\"); # Project identifier\n",
    "conn = dbapi.connect(client);\n",
    "cursor = conn.cursor();\n",
    "import google.auth\n",
    "\n",
    "credentials, your_project_id = google.auth.default( scopes=[\"https://www.googleapis.com/auth/cloud-platform\"])\n",
    "bqclient = bigquery.Client(credentials=credentials, project=\"mining-clinical-decisions\",)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_list=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unique Workstations\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of note. I did not change TPAP since it really didn,t matter what we called that table, so I left it as it was. All other mentions to TPA were changed from old code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH TPAP_ACTUAL_TIMES AS\n",
    "(\n",
    "SELECT \n",
    "    AL.pat_enc_csn_id_coded, \n",
    "    min(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY)) as cath_time,\n",
    "    min(DATETIME_SUB(AL.emergencyAdmitTime, INTERVAL TMP.JITTER DAY)) as emergency_admit_time, \n",
    "    min(DATETIME_SUB(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_start_time,\n",
    "    min(DATETIME_ADD(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_end_time,\n",
    "\n",
    "FROM `rose_team.cohort_AL` as AL,\n",
    "  `rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid = TMP.ANON_ID\n",
    "GROUP BY AL.pat_enc_csn_id_coded\n",
    "ORDER BY cath_time\n",
    "),\n",
    "\n",
    "PROVIDER_MAPPING AS\n",
    "(\n",
    "SELECT pat_enc_csn_id_coded, user_deid AS provider_id, emergencyAdmitTime, cathTime, count(*) AS even_count\n",
    "  FROM `rose_team.cohort_AL` as AL\n",
    "  WHERE \n",
    "    metric_name like \"%Lab%\" OR metric_name like \"% lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Result%\" OR metric_name like \"%result%\" \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "  \n",
    "  GROUP BY pat_enc_csn_id_coded, user_deid,emergencyAdmitTime, cathTime\n",
    "),\n",
    "\n",
    "TT AS\n",
    "(\n",
    "SELECT \n",
    "  *\n",
    "FROM \n",
    "  TPAP_ACTUAL_TIMES\n",
    "INNER JOIN\n",
    "  PROVIDER_MAPPING\n",
    "USING \n",
    "  (pat_enc_csn_id_coded)\n",
    "),\n",
    "\n",
    "\n",
    "AL_ALL_ACTUAL_TIMES AS\n",
    "(SELECT AL.*, DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real\n",
    "FROM `rose_team.shc_access_log_de_dep_id` as AL,\n",
    "`rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND metric_name NOT LIKE 'Inpatient Patient Lists activity accessed'\n",
    "ORDER BY AL.rit_uid\n",
    "),\n",
    "\n",
    "ALL_TT_ENCOUNTERS AS (\n",
    "\n",
    "SELECT \n",
    "  TT.*, access_time_real, metric_name, workstation_id\n",
    "FROM \n",
    "  TT\n",
    "INNER JOIN\n",
    "  AL_ALL_ACTUAL_TIMES\n",
    "ON\n",
    "  (AL_ALL_ACTUAL_TIMES.user_deid = TT.provider_id)\n",
    "AND\n",
    "  access_time_real BETWEEN tw_start_time AND tw_end_time\n",
    "),\n",
    "\n",
    "ALL_TT_METRICS AS (\n",
    "\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    provider_id,\n",
    "    COUNT(DISTINCT workstation_id) AS num_unq_wrkstn\n",
    "FROM \n",
    "    ALL_TT_ENCOUNTERS\n",
    "GROUP BY 1,2,3,4\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    AVG(num_unq_wrkstn) AS num_unq_wrkstn\n",
    "FROM \n",
    "    ALL_TT_METRICS\n",
    "GROUP BY \n",
    "    1,2,3 \n",
    "    ORDER BY \n",
    "    cath_time\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe = bqclient.query(query).result().to_dataframe()\n",
    "print(dataframe)\n",
    "dataframe= dataframe[['pat_enc_csn_id_coded', 'num_unq_wrkstn']]\n",
    "print(dataframe.head())\n",
    "df_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH TPAP_ACTUAL_TIMES AS\n",
    "(\n",
    "SELECT\n",
    "AL.rit_uid,\n",
    "AL.pat_enc_csn_id_coded,\n",
    "min(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY)) as cath_time,\n",
    "min(DATETIME_SUB(AL.emergencyAdmitTime, INTERVAL TMP.JITTER DAY)) as emergency_admit_time,\n",
    "min(DATETIME_SUB(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_start_time,\n",
    "min(DATETIME_ADD(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_end_time,\n",
    "FROM `rose_team.cohort_AL` as AL,\n",
    "`rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid = TMP.ANON_ID\n",
    "GROUP BY AL.rit_uid, AL.pat_enc_csn_id_coded\n",
    "ORDER BY cath_time\n",
    "),\n",
    "PROVIDER_MAPPING AS\n",
    "(\n",
    "SELECT pat_enc_csn_id_coded, user_deid AS provider_id, emergencyAdmitTime, cathTime, count(*) AS even_count\n",
    "FROM `rose_team.cohort_AL` as AL\n",
    "WHERE\n",
    "(metric_name like \"%Lab%\" OR metric_name like \"% lab%\"\n",
    "OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "OR metric_name like \"%Order%\" OR metric_name like \"%order%\"\n",
    "OR metric_name like \"%Result%\" OR metric_name like \"%result%\"\n",
    "OR metric_name like \"%Medications%\" OR metric_name like \"%medications%\"\n",
    "OR metric_name like \"%MAR%\"\n",
    "OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    ")\n",
    "GROUP BY pat_enc_csn_id_coded, user_deid, emergencyAdmitTime, cathTime\n",
    "),\n",
    "TT AS\n",
    "(\n",
    "SELECT\n",
    "*\n",
    "FROM\n",
    "TPAP_ACTUAL_TIMES\n",
    "INNER JOIN\n",
    "PROVIDER_MAPPING\n",
    "USING\n",
    "(pat_enc_csn_id_coded)\n",
    "),\n",
    "-- Generate AL with actual times\n",
    "AL_ALL_ACTUAL_TIMES AS\n",
    "(SELECT AL.*, DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real\n",
    "FROM `rose_team.shc_access_log_de_dep_id` as AL,\n",
    "`rose_team.tmp` as TMP\n",
    "WHERE\n",
    "AL.rit_uid=TMP.ANON_ID\n",
    "AND metric_name NOT LIKE 'Inpatient Patient Lists activity accessed'\n",
    "ORDER BY AL.rit_uid\n",
    "),\n",
    "FILTERED_EVENTS AS (\n",
    "SELECT\n",
    "TT.*,\n",
    "AL_ALL_ACTUAL_TIMES.access_time_real,\n",
    "AL_ALL_ACTUAL_TIMES.metric_name,\n",
    "AL_ALL_ACTUAL_TIMES.workstation_id,\n",
    "AL_ALL_ACTUAL_TIMES.rit_uid AS patient_id,\n",
    "LEAD(AL_ALL_ACTUAL_TIMES.rit_uid)\n",
    "OVER (PARTITION BY pat_enc_csn_id_coded, provider_id ORDER BY access_time_real ASC) AS next_patient_id\n",
    "FROM\n",
    "TT\n",
    "INNER JOIN\n",
    "AL_ALL_ACTUAL_TIMES\n",
    "ON\n",
    "AL_ALL_ACTUAL_TIMES.user_deid = TT.provider_id\n",
    "WHERE\n",
    "access_time_real BETWEEN tw_start_time AND tw_end_time\n",
    "ORDER BY\n",
    "pat_enc_csn_id_coded, provider_id, access_time_real\n",
    "),\n",
    "TASK_SWITCHING AS\n",
    "(\n",
    "SELECT\n",
    "*,\n",
    "(CASE WHEN patient_id = next_patient_id THEN 0 ELSE 1 END) AS task_switched\n",
    "FROM FILTERED_EVENTS\n",
    "),\n",
    "PROVIDER_LEVEL_SWITCHING AS\n",
    "(\n",
    "SELECT\n",
    "DATETIME_DIFF(cath_time, emergency_admit_time, MINUTE) AS cath_min,\n",
    "pat_enc_csn_id_coded,\n",
    "provider_id,\n",
    "SUM(task_switched) AS total_switching,\n",
    "COUNT(distinct(patient_id))-1 AS view_count\n",
    "FROM TASK_SWITCHING\n",
    "GROUP BY 1, pat_enc_csn_id_coded, provider_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_min,\n",
    "    AVG(total_switching) AS avg_task_switching,\n",
    "    AVG(view_count) AS view_count\n",
    "FROM \n",
    "    PROVIDER_LEVEL_SWITCHING\n",
    "GROUP BY \n",
    "    1,2\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update April 15th, 2022: 'View count' removed from the dataframe that we are adding to DF list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe = bqclient.query(query).result().to_dataframe()\n",
    "dataframe= dataframe[['pat_enc_csn_id_coded', 'cath_min', 'avg_task_switching']]\n",
    "print(dataframe.head())\n",
    "df_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chart views\n",
    "Robert Edits: Changing this so that we are measuring the number of distinct views of other patients, not the total number of views of other patient's \"%encounter%\" metrics.\n",
    "As of January 14th - Trying to determine why there are 252 unique CSN's in one table versus 243 in another.\n",
    "Update: April 15th, 236 chart views versus 228 actual patients.\n",
    "Robert searched the code and found this table had a unique event \"reports\" which was added to the definiton to find providers. Deleted that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query='''\n",
    "WITH TPAP_ACTUAL_TIMES AS\n",
    "(\n",
    "SELECT \n",
    "    AL.rit_uid,\n",
    "    AL.pat_enc_csn_id_coded, \n",
    "    min(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY)) as cath_time,\n",
    "    min(DATETIME_SUB(AL.emergencyAdmitTime, INTERVAL TMP.JITTER DAY)) as emergency_admit_time, \n",
    "    min(DATETIME_SUB(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_start_time,\n",
    "    min(DATETIME_ADD(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_end_time,\n",
    "FROM `rose_team.cohort_AL` as AL,\n",
    "  `rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid = TMP.ANON_ID\n",
    "GROUP BY AL.rit_uid, AL.pat_enc_csn_id_coded\n",
    "ORDER BY cath_time\n",
    "),\n",
    "PROVIDER_MAPPING AS\n",
    "(\n",
    "SELECT pat_enc_csn_id_coded, user_deid AS provider_id, emergencyAdmitTime, cathTime, count(*) AS even_count\n",
    "  FROM `rose_team.cohort_AL` as AL\n",
    "  WHERE \n",
    "    (metric_name like \"%Lab%\" OR metric_name like \"% lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"    \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "    )\n",
    "  \n",
    "  GROUP BY pat_enc_csn_id_coded, user_deid,emergencyAdmitTime, cathTime\n",
    "),\n",
    "TT AS\n",
    "(\n",
    "SELECT \n",
    "  *\n",
    "FROM \n",
    "  TPAP_ACTUAL_TIMES\n",
    "INNER JOIN\n",
    "  PROVIDER_MAPPING\n",
    "USING \n",
    "  (pat_enc_csn_id_coded)\n",
    "),\n",
    "  -- Generate AL with actual times where metric name is Encounter%. \n",
    "  -- Every chart view should have at least one Encounter metric name.\n",
    "  -- For the MOORE work, we do not want this restriction. Removing it.\n",
    "AL_ALL_ACTUAL_TIMES AS\n",
    "(SELECT AL.*, DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real\n",
    "FROM `rose_team.shc_access_log_de_dep_id` as AL,\n",
    "`rose_team.tmp` as TMP\n",
    "WHERE \n",
    "    AL.rit_uid=TMP.ANON_ID\n",
    "ORDER BY AL.rit_uid\n",
    "),\n",
    "FILTERED_EVENTS AS (\n",
    "SELECT \n",
    "  TT.*, \n",
    "  TT.rit_uid AS INDEX_UID,\n",
    "  AL_ALL_ACTUAL_TIMES.access_time_real, \n",
    "  AL_ALL_ACTUAL_TIMES.metric_name, \n",
    "  AL_ALL_ACTUAL_TIMES.workstation_id,\n",
    "  AL_ALL_ACTUAL_TIMES.rit_uid AS other_uid  \n",
    "FROM \n",
    "  TT\n",
    "INNER JOIN\n",
    "  AL_ALL_ACTUAL_TIMES\n",
    "ON\n",
    "    AL_ALL_ACTUAL_TIMES.user_deid = TT.provider_id\n",
    "WHERE\n",
    "  access_time_real BETWEEN tw_start_time AND tw_end_time\n",
    "ORDER BY \n",
    "    pat_enc_csn_id_coded, provider_id, access_time_real\n",
    "),\n",
    "-- Subtract 1 from the counts since we don't want to include the index patient.\n",
    "PROVIDER_LEVEL_METRIC AS\n",
    "(\n",
    "SELECT \n",
    "    -- DATETIME_DIFF(cath_time, emergency_admit_time, MINUTE) AS cath_min,\n",
    "    pat_enc_csn_id_coded, \n",
    "    provider_id, \n",
    "    COUNT(DISTINCT(other_uid)) - 1 AS view_count \n",
    "    FROM FILTERED_EVENTS\n",
    "GROUP BY pat_enc_csn_id_coded, provider_id\n",
    ")\n",
    "\n",
    "SELECT pat_enc_csn_id_coded, AVG(view_count) AS view_count\n",
    "FROM PROVIDER_LEVEL_METRIC\n",
    "GROUP BY 1\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe = bqclient.query(query).result().to_dataframe()\n",
    "dataframe= dataframe[['pat_enc_csn_id_coded', 'view_count']]\n",
    "print(dataframe)\n",
    "df_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#bad_df[bad_df.pat_enc_csn_id_coded.isin(dataframe.pat_enc_csn_id_coded) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days Since Last TPA Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query='''\n",
    "WITH TPAP_ACTUAL_TIMES AS\n",
    "(\n",
    "SELECT \n",
    "    AL.pat_enc_csn_id_coded, \n",
    "    min(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY)) as cath_time,\n",
    "    min(DATETIME_SUB(AL.emergencyAdmitTime, INTERVAL TMP.JITTER DAY)) as emergency_admit_time, \n",
    "    min(DATETIME_SUB(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_start_time,\n",
    "    min(DATETIME_ADD(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_end_time,\n",
    "\n",
    "FROM `rose_team.cohort_AL` as AL,\n",
    "  `rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid = TMP.ANON_ID\n",
    "GROUP BY AL.pat_enc_csn_id_coded\n",
    "ORDER BY cath_time\n",
    "),\n",
    "\n",
    "PROVIDER_MAPPING AS\n",
    "(\n",
    "SELECT pat_enc_csn_id_coded, user_deid AS provider_id, emergencyAdmitTime, cathTime, count(*) AS even_count\n",
    "  FROM `rose_team.cohort_AL` as AL\n",
    "  WHERE \n",
    "    metric_name like \"%Lab%\" OR metric_name like \"% lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Result%\" OR metric_name like \"%result%\" \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "\n",
    "  \n",
    "  GROUP BY pat_enc_csn_id_coded, user_deid,emergencyAdmitTime, cathTime\n",
    "),\n",
    "\n",
    "TT AS\n",
    "(\n",
    "SELECT \n",
    "  *\n",
    "FROM \n",
    "  TPAP_ACTUAL_TIMES\n",
    "INNER JOIN\n",
    "  PROVIDER_MAPPING\n",
    "USING \n",
    "  (pat_enc_csn_id_coded)\n",
    "),\n",
    "\n",
    "  -- Generate AL with actual times\n",
    "AL_ALL_ACTUAL_TIMES AS\n",
    "(SELECT AL.*, DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real\n",
    "FROM `rose_team.shc_access_log_de_dep_id` as AL,\n",
    "`rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND metric_name NOT LIKE 'Inpatient Patient Lists activity accessed'\n",
    "ORDER BY AL.rit_uid\n",
    "),\n",
    "\n",
    "ALL_TT_ENCOUNTERS AS (\n",
    "\n",
    "SELECT \n",
    "  TT.*, access_time_real, metric_name, workstation_id\n",
    "FROM \n",
    "  TT\n",
    "INNER JOIN\n",
    "  AL_ALL_ACTUAL_TIMES\n",
    "ON\n",
    "  (AL_ALL_ACTUAL_TIMES.user_deid = TT.provider_id)\n",
    "AND\n",
    "  access_time_real BETWEEN tw_start_time AND tw_end_time\n",
    "),\n",
    "\n",
    "ALL_TT_METRICS AS (\n",
    "\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    provider_id,\n",
    "    DATETIME_DIFF(cath_time, LAG(emergency_admit_time) -- ,1,DATETIME(2000,1,1,0,0,0)\n",
    "    OVER (PARTITION BY provider_id ORDER BY emergency_admit_time ASC), DAY) AS day_since_last_cath\n",
    "FROM \n",
    "    ALL_TT_ENCOUNTERS\n",
    "GROUP BY 1,2,3,4\n",
    "ORDER BY emergency_admit_time\n",
    "),\n",
    "\n",
    "-- Changing this so that the default for missing values is not 30, but is null.\n",
    "ALL_TT_METRICS_2 AS (\n",
    "\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    provider_id,\n",
    "    (CASE WHEN day_since_last_cath IS NOT NULL THEN day_since_last_cath ELSE NULL END) AS day_since_last_cath\n",
    "FROM \n",
    "    ALL_TT_METRICS\n",
    "),\n",
    "-- REMOVE ANY ENCOUNTERS WITHIN THE 1st 30 days of the study period so that we have a bit of a washout period to\n",
    "-- accumlate strokes cases for providers.\n",
    "FIND_EARLIEST_ENC AS (\n",
    "SELECT \n",
    "    DATETIME_ADD(MIN(cath_time), INTERVAL 30 DAY) as CUTOFF_DATE FROM ALL_TT_METRICS_2\n",
    "),\n",
    "EARLIEST_TO_DELETE AS (\n",
    "SELECT\n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    provider_id,\n",
    "    case when cath_time >= CUTOFF_DATE then day_since_last_cath else NULL end AS day_since_last_cath\n",
    "FROM\n",
    "    ALL_TT_METRICS_2, FIND_EARLIEST_ENC\n",
    "),\n",
    "FINAL AS(\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    MIN(day_since_last_cath) AS day_since_last_cath\n",
    "FROM \n",
    "    EARLIEST_TO_DELETE\n",
    "GROUP BY \n",
    "    1,2,3\n",
    ")\n",
    "\n",
    "SELECT * FROM FINAL\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe = bqclient.query(query).result().to_dataframe()\n",
    "dataframe = dataframe[['pat_enc_csn_id_coded', 'day_since_last_cath']]\n",
    "print(dataframe)\n",
    "df_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update: January 9th, 2023 CCR has made edits up to here to change \"tpa\" to \"cath\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of joint TPA cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a table of treatment team, do not filter down to docs & nurses.\n",
    "query_1= '''\n",
    "CREATE OR REPLACE TABLE `mining-clinical-decisions.rose_team.treatment_team`  AS\n",
    "WITH TPAP_ACTUAL_TIMES AS\n",
    "(\n",
    "SELECT \n",
    "    AL.pat_enc_csn_id_coded, \n",
    "    min(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY)) as cath_time,\n",
    "    min(DATETIME_SUB(AL.emergencyAdmitTime, INTERVAL TMP.JITTER DAY)) as emergency_admit_time, \n",
    "    min(DATETIME_SUB(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_start_time,\n",
    "    min(DATETIME_ADD(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_end_time,\n",
    "\n",
    "FROM `rose_team.cohort_AL` as AL,\n",
    "  `rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid = TMP.ANON_ID\n",
    "GROUP BY AL.pat_enc_csn_id_coded\n",
    "ORDER BY cath_time\n",
    "),\n",
    "\n",
    "PROVIDER_MAPPING AS\n",
    "(\n",
    "SELECT pat_enc_csn_id_coded, user_deid AS provider_id, emergencyAdmitTime, cathTime, count(*) AS even_count\n",
    "  FROM `rose_team.cohort_AL` as AL\n",
    "  WHERE \n",
    "    metric_name like \"%Lab%\" OR metric_name like \"% lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "  GROUP BY pat_enc_csn_id_coded, user_deid,emergencyAdmitTime, cathTime\n",
    "),\n",
    "\n",
    "TT AS\n",
    "(\n",
    "SELECT \n",
    "  *\n",
    "FROM \n",
    "  TPAP_ACTUAL_TIMES\n",
    "INNER JOIN\n",
    "  PROVIDER_MAPPING\n",
    "USING \n",
    "  (pat_enc_csn_id_coded)\n",
    "),\n",
    "\n",
    "  -- Generate AL with actual times\n",
    "AL_ALL_ACTUAL_TIMES AS\n",
    "(SELECT AL.*, DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real\n",
    "FROM `rose_team.shc_access_log_de_dep_id` as AL,\n",
    "`rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND metric_name NOT LIKE 'Inpatient Patient Lists activity accessed'\n",
    "ORDER BY AL.rit_uid\n",
    "),\n",
    "\n",
    "ALL_TT_ENCOUNTERS AS (\n",
    "\n",
    "SELECT \n",
    "  TT.*, access_time_real, metric_name, workstation_id\n",
    "FROM \n",
    "  TT\n",
    "INNER JOIN\n",
    "  AL_ALL_ACTUAL_TIMES\n",
    "ON\n",
    "  (AL_ALL_ACTUAL_TIMES.user_deid = TT.provider_id)\n",
    "AND\n",
    "  access_time_real BETWEEN tw_start_time AND tw_end_time\n",
    "),\n",
    "\n",
    "ALL_TT_METRICS AS (\n",
    "\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    tw_start_time, tw_end_time, \n",
    "    provider_id AS prov_id, count(*) AS n\n",
    "FROM \n",
    "    ALL_TT_ENCOUNTERS\n",
    "GROUP BY 1,2,3,4,5,6\n",
    "ORDER BY emergency_admit_time\n",
    ")\n",
    "\n",
    "SELECT * FROM ALL_TT_METRICS\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like query_2 does a cartesian product within each index encounter, and then counts pairs of users. I think this double counts users.\n",
    "Ex: \n",
    "pat_enc_csn_id_coded, provider_id\n",
    "1,1\n",
    "1,2\n",
    "1,3\n",
    "\n",
    "the cartesian product contatenated pair would be:\n",
    "1,11\n",
    "1,12\n",
    "1,13\n",
    "1,21\n",
    "1,22\n",
    "1,23\n",
    "1,31\n",
    "1,32\n",
    "1,33\n",
    "\n",
    "implying 9 pairings, but really there are only 6\n",
    "1,11\n",
    "1,12\n",
    "1,13\n",
    "1,22\n",
    "1,23\n",
    "1,33\n",
    "\n",
    "because, eg, 12 & 21 are the same.\n",
    "\n",
    "The window function count works fine, but I'm rewriting it so that it more explicitly matches UCSF/KPNC code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query_2='''\n",
    "WITH ALL_TT_METRICS AS\n",
    "(SELECT * FROM `mining-clinical-decisions.rose_team.treatment_team` ),\n",
    "ALL_TT_METRICS_2 AS (\n",
    "SELECT \n",
    "    DISTINCT\n",
    "    ALL_TT_METRICS.pat_enc_csn_id_coded,\n",
    "    ALL_TT_METRICS.cath_time,\n",
    "    ALL_TT_METRICS.emergency_admit_time,\n",
    "    case when ALL_TT_METRICS.PROV_ID > ALL_TT_METRICS_COPY.PROV_ID\n",
    "        then concat(ALL_TT_METRICS.PROV_ID,'_', ALL_TT_METRICS_COPY.PROV_ID) \n",
    "        else concat(ALL_TT_METRICS_COPY.PROV_ID,'_', ALL_TT_METRICS.PROV_ID) end AS joint_providers\n",
    "FROM \n",
    "    ALL_TT_METRICS\n",
    "INNER JOIN \n",
    "    ALL_TT_METRICS AS ALL_TT_METRICS_COPY\n",
    "ON\n",
    "    ALL_TT_METRICS.pat_enc_csn_id_coded = ALL_TT_METRICS_COPY.pat_enc_csn_id_coded and\n",
    "    ALL_TT_METRICS.cath_time = ALL_TT_METRICS_COPY.cath_time and\n",
    "    ALL_TT_METRICS.emergency_admit_time = ALL_TT_METRICS_COPY.emergency_admit_time and \n",
    "    ALL_TT_METRICS.PROV_ID != ALL_TT_METRICS_COPY.PROV_ID \n",
    "),\n",
    "SHARED_ENC_COUNT AS (\n",
    "    SELECT \n",
    "    a.pat_enc_csn_id_coded,\n",
    "    a.cath_time,\n",
    "    a.emergency_admit_time,\n",
    "    a.joint_providers,\n",
    "    count(DISTINCT(b.PAT_ENC_CSN_ID_CODED)) as cath_count_within_6mo\n",
    "    FROM ALL_TT_METRICS_2 A \n",
    "    LEFT join ALL_TT_METRICS_2 B\n",
    "    on a.joint_providers = b.joint_providers and b.emergency_admit_time \n",
    "        between DATETIME_SUB(a.emergency_admit_time, INTERVAL 6 MONTH) and a.emergency_admit_time\n",
    "    and a.pat_enc_csn_id_coded != b.pat_enc_csn_id_coded\n",
    "    GROUP BY \n",
    "    a.pat_enc_csn_id_coded,\n",
    "    a.cath_time,\n",
    "    a.emergency_admit_time,\n",
    "    a.joint_providers\n",
    "), WASHOUT_DATE as (\n",
    "    select DATETIME_ADD(min(cath_time), INTERVAL 6 MONTH) as WASHOUT_DATE from SHARED_ENC_COUNT\n",
    "), WASHED_JOINT_PROV_LEVEL as (\n",
    "    select  \n",
    "    a.pat_enc_csn_id_coded,\n",
    "    a.cath_time,\n",
    "    a.emergency_admit_time,\n",
    "    a.joint_providers,\n",
    "    case when cath_time < wo.WASHOUT_DATE then NULL else cath_count_within_6mo end as cath_count_within_6mo\n",
    "    from SHARED_ENC_COUNT a, WASHOUT_DATE wo \n",
    "), FINAL as (\n",
    "SELECT \n",
    "    pat_enc_csn_id_coded,\n",
    "    cath_time,\n",
    "    emergency_admit_time,\n",
    "    AVG(cath_count_within_6mo) AS joint_cath_count_within_6mo\n",
    "FROM \n",
    "    WASHED_JOINT_PROV_LEVEL\n",
    "GROUP BY \n",
    "    1,2,3\n",
    ")\n",
    "SELECT * FROM FINAL\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = bqclient.query(query_1).result().to_dataframe()\n",
    "print('query 1 executed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = bqclient.query(query_2).result().to_dataframe()\n",
    "dataframe = dataframe[['pat_enc_csn_id_coded', 'joint_cath_count_within_6mo']]\n",
    "print(dataframe)\n",
    "df_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint Experience: USING KPNC/UCSF APPROACH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query_ucsf='''\n",
    "WITH TT AS\n",
    "(SELECT * FROM `mining-clinical-decisions.rose_team.treatment_team` ),\n",
    "  -- Generate AL with actual times\n",
    "AL_ALL_ACTUAL_TIMES AS\n",
    "(SELECT AL.*, DATETIME_SUB(AL.access_time_jittered, INTERVAL TMP.JITTER DAY) as access_time_real\n",
    "FROM `rose_team.shc_access_log_de_dep_id` as AL,\n",
    "`rose_team.tmp` as TMP\n",
    "WHERE AL.rit_uid=TMP.ANON_ID\n",
    "    AND metric_name NOT LIKE 'Inpatient Patient Lists activity accessed'\n",
    "ORDER BY AL.rit_uid\n",
    "),\n",
    "ALL_TT_AL_DATA AS (\n",
    "SELECT \n",
    "  TT.*, csn, access_time_real, metric_name, workstation_id\n",
    "FROM \n",
    "  TT\n",
    "INNER JOIN\n",
    "  AL_ALL_ACTUAL_TIMES\n",
    "ON\n",
    "  (AL_ALL_ACTUAL_TIMES.user_deid = TT.prov_id)\n",
    "AND\n",
    "  access_time_real BETWEEN tw_start_time AND tw_end_time\n",
    "),\n",
    "-- FIND ANY COMBO OF USERS WHO SHARE A CSN IN THE AUDIT LOG DATA\n",
    "WINDOWS_2 AS\n",
    "( SELECT DISTINCT PAT_ENC_CSN_ID_CODED, datetime_sub(CATH_TIME, INTERVAL 6 MONTH) as WINDOW_START,\n",
    "CATH_TIME as WINDOW_END from TT),\n",
    "WINDOW_ENCS AS \n",
    "(SELECT DISTINCT \n",
    "    WINDOWS_2.PAT_ENC_CSN_ID_CODED,\n",
    "    ALL_TT_AL_DATA.PROV_ID,\n",
    "    ALL_TT_AL_DATA.CSN\n",
    "    FROM WINDOWS_2, ALL_TT_AL_DATA\n",
    "    where ALL_TT_AL_DATA.access_time_real between WINDOWS_2.WINDOW_START and WINDOWS_2.WINDOW_END\n",
    "    ),\n",
    "-- ASSIGN SHARED ENCOUNTERS TO A GIVEN INDEX ENCOUNTER\n",
    "WINDOW_ENCS_TT as (\n",
    "    SELECT \n",
    "        a.pat_enc_csn_id_coded, a.prov_id, a.CSN \n",
    "    FROM WINDOW_ENCS a \n",
    "    INNER JOIN TT b \n",
    "    on a.PROV_ID = b.PROV_ID and a.PAT_ENC_CSN_ID_CODED = b.PAT_ENC_CSN_ID_CODED\n",
    "    where a.CSN is not null\n",
    "),\n",
    "MUTUAL_ENCS as (\n",
    "    SELECT \n",
    "    DISTINCT \n",
    "        a.pat_enc_csn_id_coded, a.CSN,\n",
    "        case when a.PROV_ID > b.PROV_ID\n",
    "            then concat(a.PROV_ID, '_', b.PROV_ID) \n",
    "            else concat(b.PROV_ID, '_', a.PROV_ID) end as joint_providers\n",
    "    FROM WINDOW_ENCS_TT a \n",
    "    INNER JOIN WINDOW_ENCS_TT b\n",
    "    on a.csn = b.csn and a.PAT_ENC_CSN_ID_CODED = b.PAT_ENC_CSN_ID_CODED and a.PROV_ID != b.PROV_ID\n",
    "),\n",
    "EDGES as (\n",
    "    SELECT\n",
    "        PAT_ENC_CSN_ID_CODED, joint_providers,\n",
    "        count(distinct(case when PAT_ENC_CSN_ID_CODED = CSN then null else CSN end)) as EDGE_WEIGHT\n",
    "    FROM MUTUAL_ENCS\n",
    "    GROUP BY \n",
    "        PAT_ENC_CSN_ID_CODED, joint_providers\n",
    "), \n",
    "-- For any provider pairs that don't share a CSN, we need to include their edge weights too (which will be 0)\n",
    "TT_MUTUAL AS (\n",
    "    SELECT \n",
    "    DISTINCT \n",
    "        a.pat_enc_csn_id_coded, a.cath_time,\n",
    "        case when a.PROV_ID > b.PROV_ID\n",
    "            then concat(a.PROV_ID, '_', b.PROV_ID) \n",
    "            else concat(b.PROV_ID, '_', a.PROV_ID) end as joint_providers\n",
    "    FROM TT a \n",
    "    INNER JOIN TT b\n",
    "    on a.PAT_ENC_CSN_ID_CODED = b.PAT_ENC_CSN_ID_CODED and a.PROV_ID != b.PROV_ID\n",
    "),\n",
    "EDGE_TEAM as (\n",
    "    SELECT \n",
    "        a.PAT_ENC_CSN_ID_CODED, a.cath_time, a.joint_providers, \n",
    "            coalesce(b.EDGE_WEIGHT, 0) as EDGE_WEIGHT\n",
    "    FROM TT_MUTUAL a \n",
    "    LEFT JOIN EDGES b \n",
    "    on a.joint_providers = b.joint_providers and a.PAT_ENC_CSN_ID_CODED = b.PAT_ENC_CSN_ID_CODED \n",
    "), \n",
    "FINAL as (\n",
    "    SELECT PAT_ENC_CSN_ID_CODED, CATH_TIME,\n",
    "        AVG(EDGE_WEIGHT) as CATH_ANY_EXPERIENCE\n",
    "    from EDGE_TEAM\n",
    "    GROUP BY \n",
    "        PAT_ENC_CSN_ID_CODED, CATH_TIME\n",
    "        \n",
    ") \n",
    "    SELECT pat_enc_csn_id_coded, \n",
    "        case when CATH_TIME < datetime(2011,5,17,0,0,0) then NULL \n",
    "            else CATH_ANY_EXPERIENCE end \n",
    "            as CATH_ANY_EXPERIENCE \n",
    "        FROM FINAL\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe = bqclient.query(query_ucsf).result().to_dataframe()\n",
    "dataframe = dataframe[['pat_enc_csn_id_coded', 'CATH_ANY_EXPERIENCE']]\n",
    "print(dataframe)\n",
    "df_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update: March 16th, 2022 - Attempting to remove duplicate encounter ID's from the list of encounters. Total coming to 254 versus 244 from other sources. In 5 cases, there are multiple tPA admin times for the same encounter.\n",
    "\n",
    "When we filtered by treatment team - 10 cases are removed. So presumes that these 10 cases have treatment team size = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update: April 15th, 2022 - Removed all cases (16 in total) where patient arrived in Stanford ED as a John Doe and so merged MRN limit Audit log measure utility due to missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "query_demo='''\n",
    "WITH TPAP_ACTUAL_TIMES AS\n",
    "(\n",
    "SELECT \n",
    "  AL.pat_enc_csn_id_coded, \n",
    "  AL.RIT_UID,\n",
    "  AL.emergencyAdmitTime as ORIG_ED_ADMIT_TIME,\n",
    "  min(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY)) as cath_time,\n",
    "  min(DATETIME_SUB(AL.emergencyAdmitTime, INTERVAL TMP.JITTER DAY)) as emergency_admit_time, \n",
    "  min(DATETIME_SUB(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_start_time,\n",
    "  min(DATETIME_ADD(DATETIME_SUB(AL.cathTime, INTERVAL TMP.JITTER DAY), INTERVAL 1 HOUR)) as tw_end_time,\n",
    "FROM `mining-clinical-decisions.rose_team.cohort_AL`as AL,\n",
    "`mining-clinical-decisions.rose_team.tmp`as TMP\n",
    "WHERE AL.rit_uid = TMP.ANON_ID\n",
    "GROUP BY AL.pat_enc_csn_id_coded, AL.rit_uid, AL.emergencyAdmitTime\n",
    "ORDER BY cath_time\n",
    "),\n",
    "\n",
    "PROVIDER_MAPPING AS\n",
    "(\n",
    "SELECT pat_enc_csn_id_coded, user_deid AS provider_id, emergencyAdmitTime, cathTime, count(*) AS even_count\n",
    "  FROM `mining-clinical-decisions.rose_team.cohort_AL` as AL\n",
    "  WHERE \n",
    "    metric_name like \"%Lab%\" OR metric_name like \"% lab%\"\n",
    "    OR metric_name like \"%Encounter%\" OR metric_name like \"%encounter%\"\n",
    "    OR metric_name like \"%Flowchart%\" OR metric_name like \"%flowchart%\"\n",
    "    OR metric_name like \"%Order%\" OR metric_name like \"%order%\"   \n",
    "    OR metric_name like \"%Result%\" OR metric_name like \"%result%\" \n",
    "    OR metric_name like \"%Medications%\" OR metric_name like \"%medications%\"\n",
    "    OR metric_name like \"%MAR%\" \n",
    "    OR metric_name like \"%Note%\" OR metric_name like \"%note%\"\n",
    "    OR metric_name like \"%History%\" OR metric_name like \"%history%\"\n",
    "    OR metric_name like \"%Imag%\" OR metric_name like \"%imag%\"\n",
    "  GROUP BY pat_enc_csn_id_coded, user_deid, emergencyAdmitTime, cathTime\n",
    "),\n",
    "TT AS\n",
    "( \n",
    "  SELECT DISTINCT \n",
    "        AL.pat_enc_csn_id_coded,\n",
    "        al.rit_uid, \n",
    "        dm.gender, \n",
    "        dm.canonical_race, \n",
    "        dm.canonical_ethnicity,\n",
    "        EXTRACT(YEAR FROM AL.emergency_admit_time) AS year_tpa,\n",
    "        DATETIME_DIFF(AL.ORIG_ED_ADMIT_TIME, DM.birth_date_jittered, YEAR) AS age,\n",
    "        DATETIME_DIFF(cath_time,emergency_admit_time, MINUTE) AS cath_minutes\n",
    "FROM \n",
    "  TPAP_ACTUAL_TIMES al\n",
    "INNER JOIN PROVIDER_MAPPING tm\n",
    "  ON (al.pat_enc_csn_id_coded = tm.pat_enc_csn_id_coded)\n",
    "INNER JOIN `mining-clinical-decisions.starr_datalake2018.demographic` AS DM\n",
    "  ON (DM.rit_uid = AL.rit_uid)\n",
    "),\n",
    "demo as (\n",
    "SELECT DISTINCT \n",
    "    pat_enc_csn_id_coded, \n",
    "    rit_uid,\n",
    "    gender,\n",
    "    canonical_ethnicity as ethnicity,\n",
    "    case when canonical_race = 'Other' then 'Unknown' else canonical_race end as race,\n",
    "    case when age between 18 and 49 then '18-49' \n",
    "    when age between 50 and 59 then '50-59'\n",
    "    when age between 60 and 69 then '60-69'\n",
    "    when age between 70 and 79 then '70-79'\n",
    "    when age >= 80 then '80+' end as age_range, \n",
    "    year_tpa as year\n",
    "FROM TT\n",
    ")\n",
    "SELECT * FROM demo\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "March 11th - Looks like demo table has encounters that don't match elsewhere due to non-unique encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dataframe = bqclient.query(query_demo).result().to_dataframe()\n",
    "df_demo = dataframe[['pat_enc_csn_id_coded', 'gender','ethnicity','race','age_range','year']]\n",
    "print(df_demo)\n",
    "#df_list.append(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['pat_enc_csn_id_coded'],\n",
    "                                            how='outer'), df_list)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_merged = df_merged.merge(df_demo, how='inner', on='pat_enc_csn_id_coded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_merged.iloc[[137]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_merged.to_csv('all_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.matshow(df_merged.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "from scipy.stats.stats import pearsonr \n",
    "\n",
    "metric_list = ['num_unq_wrkstn', 'avg_task_switching', 'view_count', 'day_since_last_cath', 'joint_cath_count_within_6mo', 'CATH_ANY_EXPERIENCE']\n",
    "for metric in metric_list:\n",
    "    X = np.nan_to_num(df_merged[metric].to_numpy().reshape((-1,1)))\n",
    "    Y = np.nan_to_num(df_merged['cath_min'].to_numpy().reshape((-1,1)))\n",
    "    #reg = LinearRegression().fit(X, Y)\n",
    "    X = sm.add_constant(X)\n",
    "    mod = sm.OLS(Y,X)\n",
    "    fii = mod.fit()\n",
    "    print('*********', metric )\n",
    "    #print('pearson correlation')\n",
    "    #print(pearsonr(np.reshape(X,(-1,)), np.reshape((Y),(-1,))))\n",
    "    print('bivariate coefficients')\n",
    "    print(fii.conf_int(alpha=0.05, cols=None)[1])\n",
    "    print(fii.params) \n",
    "    print((np.mean(X), np.median(X), np.std(X), np.min(X), np.max(X))) \n",
    "    print(fii.summary2().tables[1]['P>|t|'].x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Build contrasts\n",
    "x_raw = df_merged[['gender','year','age_range','race','ethnicity']]\n",
    "Y = df_merged['cath_min']\n",
    "df_dummies = pd.get_dummies(x_raw, prefix=['gender','year','age_range','race','ethnicity'], prefix_sep='.', \n",
    "                            columns=['gender','year','age_range','race','ethnicity'])\n",
    "df_contrasts = df_dummies.drop(['gender.Female', 'year.2017', 'age_range.18-49', 'race.White', 'ethnicity.Non-Hispanic'], axis=1)\n",
    "model_df = df_contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_merged.hist(bins=10, column='joint_cath_count_within_6mo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_merged[df_merged.joint_cath_count_within_6mo > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "metric_list = ['num_unq_wrkstn', 'avg_task_switching', 'view_count', 'day_since_last_cath', 'joint_cath_count_within_6mo', 'CATH_ANY_EXPERIENCE']\n",
    "for metric in metric_list:\n",
    "    #X = np.nan_to_num(df_merged[metric].to_numpy().reshape((-1,1)))\n",
    "    #Y = np.nan_to_num(df_merged['tpa_min'].to_numpy().reshape((-1,1)))\n",
    "    model_df[metric] = df_merged[metric]\n",
    "    X = sm.add_constant(model_df)\n",
    "    mod = sm.OLS(Y,X,missing='drop')\n",
    "    results = mod.fit()\n",
    "    print('*********', metric )\n",
    "    print('multivariate coefficients')\n",
    "    #print(results.params.loc[metric])\n",
    "    print(results.summary())\n",
    "    print(results.conf_int(alpha=0.05, cols=None).loc[metric])\n",
    "    model_df = model_df.drop(metric,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_df['joint_cath_count_within_6mo']=np.nan_to_num(df_merged[metric].to_numpy().reshape((-1,1)))\n",
    "    #Y = np.nan_to_num(df_merged['tpa_min'].to_numpy().reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.nan_to_num(df_merged['joint_cath_count_within_6mo'].to_numpy().reshape((-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Quartile Analysis of Team Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Build contrasts\n",
    "\n",
    "# Get raw data\n",
    "x_raw = df_merged[['joint_cath_count_within_6mo', 'CATH_ANY_EXPERIENCE']]\n",
    "Y = df_merged['cath_min']\n",
    "\n",
    "# Convert to categories\n",
    "x_raw['q_joint_cath'] = pd.qcut(x_raw['joint_cath_count_within_6mo'], 4, labels=[\"1\", \"2\", \"3\", \"4\"])\n",
    "x_raw['q_any_exp'] = pd.qcut(x_raw['CATH_ANY_EXPERIENCE'], 4, labels=[\"1\", \"2\", \"3\", \"4\"])\n",
    "\n",
    "# Remove the continuous vars\n",
    "x_raw = x_raw.drop(['joint_cath_count_within_6mo', 'CATH_ANY_EXPERIENCE'], axis=1)\n",
    "\n",
    "# Convert to contrasts\n",
    "df_dummies = pd.get_dummies(x_raw, prefix=['joint', 'any'], prefix_sep='.', \n",
    "                            columns=['q_joint_cath','q_any_exp'])\n",
    "df_contrasts = df_dummies.drop(['joint.1', 'any.1'], axis=1)\n",
    "qmodel_df = df_contrasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "metric_list = [['joint.2','joint.3','joint.4'],['any.2','any.3','any.4']]\n",
    "for metric in metric_list:\n",
    "    #X = np.nan_to_num(df_merged[metric].to_numpy().reshape((-1,1)))\n",
    "    X = qmodel_df[metric]\n",
    "    Y = np.nan_to_num(df_merged['cath_min'].to_numpy().reshape((-1,1)))\n",
    "    X = sm.add_constant(X)\n",
    "    mod = sm.OLS(Y,X)\n",
    "    results = mod.fit()\n",
    "    print('*********', metric )\n",
    "    print('quartiles coefficients')\n",
    "    print(results.params.loc[metric]) \n",
    "    print(results.conf_int(alpha=0.05, cols=None).loc[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(x_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(fii.params)\n",
    "print(results.params.loc[metric]) #np.mean(X), np.median(X), np.std(X), np.min(X), np.max(X), \n",
    "print(results.conf_int(alpha=0.05, cols=None).loc[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
